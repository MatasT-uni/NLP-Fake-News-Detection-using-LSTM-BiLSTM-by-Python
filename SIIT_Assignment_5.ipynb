{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3FQCCD5KZKzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 5: Fake News Detection using LSTM + BiLSTM\n",
        "## **CSS432 Natural Language Processing and Information Retrieval**\n",
        "### Section 1\n",
        "\n",
        "---\n",
        "\n",
        "## **Objective:**\n",
        "\n",
        "\n",
        "The goal of this project is to create and assess LSTM and BiLSTM models specifically for identifying fake news. This endeavor will provide students with hands-on knowledge in the fields of natural language processing (NLP) and advanced learning strategies, encompassing areas such as text preparation, crafting model frameworks, adjusting hyperparameters, and evaluating model performance. By conducting experiments and analyzing results, students will investigate how various model configurations and parameters impact the accuracy of fake news detection, enhancing their grasp of applying deep learning techniques to text categorization challenges."
      ],
      "metadata": {
        "id": "oC0fruUqb_NI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## **Download Dataset**\n",
        "\n",
        "> [download link](https://gitlab.com/atlonxp/siit-nlp/-/raw/main/dl-rnn/fake-new-dataset.zip?ref_type=heads&inline=false )\n",
        "\n"
      ],
      "metadata": {
        "id": "pGws8duLX-0-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJTjtS97X2ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33780bb-b54b-44bb-c3a6-658ec7fc3ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 90.8M  100 90.8M    0     0  95.3M      0 --:--:-- --:--:-- --:--:-- 95.3M\n"
          ]
        }
      ],
      "source": [
        "# Download\n",
        "!curl \"https://gitlab.com/atlonxp/siit-nlp/-/raw/main/dl-rnn/fake-new-dataset.zip?ref_type=heads&inline=false\" --output \"fake-news.zip\"\n",
        "\n",
        "# Extract\n",
        "import zipfile\n",
        "with zipfile.ZipFile('fake-news.zip','r') as zip_ref:\n",
        "  zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# LSTM"
      ],
      "metadata": {
        "id": "c0fcCGz2STPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "897veh8xSp0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "metadata": {
        "id": "HJMqR9zESeUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "9W-j3olJSeny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert csv file into list"
      ],
      "metadata": {
        "id": "OHDHqEp7es59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"fake-news-dataset.csv\"\n",
        "dataset = open(filename, 'r')\n",
        "dataset_reader = csv.reader(dataset)\n",
        "\n",
        "# Set new field size limit\n",
        "csv.field_size_limit(1000000)\n",
        "\n",
        "# Convert to list\n",
        "dataset_list = list(dataset_reader)\n",
        "\n",
        "#Remove index column\n",
        "dataset_list = [row[1:] for row in dataset_list]\n",
        "print(dataset_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WihUqCYSnPH",
        "outputId": "4be08d55-17b6-4bd1-d1c5-e969c7e9ff51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['title', 'text', 'label']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the dataset"
      ],
      "metadata": {
        "id": "vLSfL234evaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(dataset_list[1:6], columns=dataset_list[0])\n",
        "df.style"
      ],
      "metadata": {
        "id": "CJdZ8JGheyXi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1a9a857-94d4-4b65-efa7-a8a8971fd9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7d7e7f617f40>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_081ef\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_081ef_level0_col0\" class=\"col_heading level0 col0\" >title</th>\n",
              "      <th id=\"T_081ef_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
              "      <th id=\"T_081ef_level0_col2\" class=\"col_heading level0 col2\" >label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_081ef_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_081ef_row0_col0\" class=\"data row0 col0\" >LAW ENFORCEMENT ON HIGH ALERT Following Threats Against Cops And Whites On 9-11By #BlackLivesMatter And #FYF911 Terrorists [VIDEO]</td>\n",
              "      <td id=\"T_081ef_row0_col1\" class=\"data row0 col1\" >No comment is expected from Barack Obama Members of the #FYF911 or #FukYoFlag and #BlackLivesMatter movements called for the lynching and hanging of white people and cops. They encouraged others on a radio show Tuesday night to  turn the tide  and kill white people and cops to send a message about the killing of black people in America.One of the F***YoFlag organizers is called  Sunshine.  She has a radio blog show hosted from Texas called,  Sunshine s F***ing Opinion Radio Show. A snapshot of her #FYF911 @LOLatWhiteFear Twitter page at 9:53 p.m. shows that she was urging supporters to  Call now!! #fyf911 tonight we continue to dismantle the illusion of white Below is a SNAPSHOT Twitter Radio Call Invite   #FYF911The radio show aired at 10:00 p.m. eastern standard time.During the show, callers clearly call for  lynching  and  killing  of white people.A 2:39 minute clip from the radio show can be heard here. It was provided to Breitbart Texas by someone who would like to be referred to as  Hannibal.  He has already received death threats as a result of interrupting #FYF911 conference calls.An unidentified black man said  when those mother f**kers are by themselves, that s when when we should start f***ing them up. Like they do us, when a bunch of them ni**ers takin  one of us out, that s how we should roll up.  He said,  Cause we already roll up in gangs anyway. There should be six or seven black mother f**ckers, see that white person, and then lynch their ass. Let s turn the tables. They conspired that if  cops started losing people,  then  there will be a state of emergency. He speculated that one of two things would happen,  a big-ass [R s?????] war,  or  ni**ers, they are going to start backin  up. We are already getting killed out here so what the f**k we got to lose? Sunshine could be heard saying,  Yep, that s true. That s so f**king true. He said,  We need to turn the tables on them. Our kids are getting shot out here. Somebody needs to become a sacrifice on their side.He said,  Everybody ain t down for that s**t, or whatever, but like I say, everybody has a different position of war.  He continued,  Because they don t give a f**k anyway.  He said again,  We might as well utilized them for that s**t and turn the tables on these n**ers. He said, that way  we can start lookin  like we ain t havin  that many casualties, and there can be more causalities on their side instead of ours. They are out their killing black people, black lives don t matter, that s what those mother f**kers   so we got to make it matter to them. Find a mother f**ker that is alone. Snap his ass, and then f***in hang him from a damn tree. Take a picture of it and then send it to the mother f**kers. We  just need one example,  and  then people will start watchin .  This will turn the tables on s**t, he said. He said this will start  a trickle-down effect.  He said that when one white person is hung and then they are just  flat-hanging,  that will start the  trickle-down effect.  He continued,  Black people are good at starting trends. He said that was how  to get the upper-hand. Another black man spoke up saying they needed to kill  cops that are killing us. The first black male said,  That will be the best method right there. Breitbart Texas previously reported how Sunshine was upset when  racist white people  infiltrated and disrupted one of her conference calls. She subsequently released the phone number of one of the infiltrators. The veteran immediately started receiving threatening calls.One of the #F***YoFlag movement supporters allegedly told a veteran who infiltrated their publicly posted conference call,  We are going to rape and gut your pregnant wife, and your f***ing piece of sh*t unborn creature will be hung from a tree. Breitbart Texas previously encountered Sunshine at a Sandra Bland protest at the Waller County Jail in Texas, where she said all white people should be killed. She told journalists and photographers,  You see this nappy-ass hair on my head?   That means I am one of those more militant Negroes.  She said she was at the protest because  these redneck mother-f**kers murdered Sandra Bland because she had nappy hair like me. #FYF911 black radicals say they will be holding the  imperial powers  that are actually responsible for the terrorist attacks on September 11th accountable on that day, as reported by Breitbart Texas. There are several websites and Twitter handles for the movement. Palmetto Star  describes himself as one of the head organizers. He said in a YouTube video that supporters will be burning their symbols of  the illusion of their superiority,  their  false white supremacy,  like the American flag, the British flag, police uniforms, and Ku Klux Klan hoods.Sierra McGrone or  Nocturnus Libertus  posted,  you too can help a young Afrikan clean their a** with the rag of oppression.  She posted two photos, one that appears to be herself, and a photo of a black man, wiping their naked butts with the American flag.For entire story: Breitbart News</td>\n",
              "      <td id=\"T_081ef_row0_col2\" class=\"data row0 col2\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_081ef_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_081ef_row1_col0\" class=\"data row1 col0\" ></td>\n",
              "      <td id=\"T_081ef_row1_col1\" class=\"data row1 col1\" >Did they post their votes for Hillary already?</td>\n",
              "      <td id=\"T_081ef_row1_col2\" class=\"data row1 col2\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_081ef_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_081ef_row2_col0\" class=\"data row2 col0\" >UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MOST CHARLOTTE RIOTERS WERE “PEACEFUL” PROTESTERS…In Her Home State Of North Carolina [VIDEO]</td>\n",
              "      <td id=\"T_081ef_row2_col1\" class=\"data row2 col1\" > Now, most of the demonstrators gathered last night were exercising their constitutional and protected right to peaceful protest in order to raise issues and create change.    Loretta Lynch aka Eric Holder in a skirt</td>\n",
              "      <td id=\"T_081ef_row2_col2\" class=\"data row2 col2\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_081ef_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_081ef_row3_col0\" class=\"data row3 col0\" >Bobby Jindal, raised Hindu, uses story of Christian conversion to woo evangelicals for potential 2016 bid</td>\n",
              "      <td id=\"T_081ef_row3_col1\" class=\"data row3 col1\" >A dozen politically active pastors came here for a private dinner Friday night to hear a conversion story unique in the context of presidential politics: how Louisiana Gov. Bobby Jindal traveled from Hinduism to Protestant Christianity and, ultimately, became what he calls an “evangelical Catholic.”\n",
              "\n",
              "Over two hours, Jindal, 42, recalled talking with a girl in high school who wanted to “save my soul,” reading the Bible in a closet so his parents would not see him and feeling a stir while watching a movie during his senior year that depicted Jesus on the cross.\n",
              "\n",
              "“I was struck, and struck hard,” Jindal told the pastors. “This was the Son of God, and He had died for our sins.”\n",
              "\n",
              "Jindal’s session with the Christian clergy, who lead congregations in the early presidential battleground states of Iowa and South Carolina, was part of a behind-the-scenes effort by the Louisiana governor to find a political base that could help propel him into the top tier of Republican candidates seeking to run for the White House in 2016.\n",
              "\n",
              "Known in GOP circles mostly for his mastery of policy issues such as health care, Jindal, a Rhodes Scholar and graduate of the Ivy League’s Brown University, does not have an obvious pool of activist supporters to help drive excitement outside his home state. So he is harnessing his religious experience in a way that has begun to appeal to parts of the GOP’s influential core of religious conservatives, many of whom have yet to find a favorite among the Republicans eyeing the presidential race.\n",
              "\n",
              "Other potential 2016 GOP candidates are wooing the evangelical base, including Sens. Rand Paul (Ky.) and Ted Cruz (Tex.) and Indiana Gov. Mike Pence.\n",
              "\n",
              "But over the weekend in Lynchburg — a mecca of sorts for evangelicals as the home of Liberty University, founded in the 1970s by the Rev. Jerry Falwell — Jindal appeared to make progress.\n",
              "\n",
              "In addition to his dinner with the pastors, he delivered a well-received “call to action” address to 40,000 Christian conservatives gathered for Liberty’s commencement ceremony, talking again about his faith while assailing what he said was President Obama’s record of attacking religious liberty.\n",
              "\n",
              "The pastors who came to meet Jindal said his intimate descriptions of his experiences stood out.\n",
              "\n",
              "“He has the convictions, and he has what it takes to communicate them,” said Brad Sherman of Solid Rock Christian Church in Coralville, Iowa. Sherman helped former Arkansas governor Mike Huckabee in his winning 2008 campaign for delegates in Iowa.\n",
              "\n",
              "Another Huckabee admirer, the Rev. C. Mitchell Brooks of Second Baptist Church in Belton, S.C., said Jindal’s commitment to Christian values and his compelling story put him “on a par” with Huckabee, who was a Baptist preacher before entering politics.\n",
              "\n",
              "The visiting pastors flew to Lynchburg over the weekend at the invitation of the American Renewal Project, a well-funded nonprofit group that encourages evangelical Christians to engage in the civic arena with voter guides, get-out-the-vote drives and programs to train pastors in grass-roots activism. The group’s founder, David Lane, has built a pastor network in politically important states such as Iowa, Missouri, Ohio and South Carolina and has led trips to Israel with Paul and others seeking to make inroads with evangelical activists.\n",
              "\n",
              "The group that Lane invited to Lynchburg included Donald Wild­mon, a retired minister and founder of the American Family Association, a prominent evangelical activist group that has influence through its network of more than 140 Christian radio stations.\n",
              "\n",
              "Most of the pastors that Lane’s organization brought to Lynchburg had not met Jindal. But they said he captured their interest recently when he stepped forward to defend Phil Robertson, patriarch of the “Duck Dynasty” television-show family, amid a controversy over disparaging remarks he made about gays in an interview with GQ magazine.\n",
              "\n",
              "Throughout his Lynchburg visit, Jindal presented himself as a willing culture warrior.\n",
              "\n",
              "During his commencement address Saturday, he took up the cause of twin brothers whose HGTV reality series about renovating and reselling houses, “Flip It Forward,” was canceled last week after a Web site revealed that they had protested against same-sex marriage at the 2012 Democratic National Convention in Charlotte.\n",
              "\n",
              "The siblings, Jason and David Benham, both Liberty graduates, attended the graduation and a private lunch with Jindal, who called the action against them “another demonstration of intolerance from the entertainment industry.”\n",
              "\n",
              "“If these guys had protested at the Republican Party convention, instead of canceling their show, HGTV would probably have given them a raise,” Jindal said as the Liberty crowd applauded.\n",
              "\n",
              "He cited the Hobby Lobby craft store chain, which faced a legal challenge after refusing to provide employees with insurance coverage for contraceptives as required under the Affordable Care Act. Members of the family that owns Hobby Lobby, who have become heroes to many religious conservatives, have said that they are morally opposed to the use of certain types of birth control and that they considered the requirement a violation of their First Amendment right to religious freedom.\n",
              "\n",
              "The family was “committed to honor the Lord by being generous employers, paying well above minimum wage and increasing salaries four years in a row even in the midst of the enduring recession,” Jindal told the Liberty graduates. “None of this matters to the Obama administration.”\n",
              "\n",
              "But for the pastors who came to see Jindal in action, the governor’s own story was the highlight of the weekend. And in many ways, he was unlike any other aspiring president these activists had met.\n",
              "\n",
              "Piyush Jindal was born in 1971, four months after his parents arrived in Baton Rouge, La., from their native India. He changed his name to Bobby as a young boy, adopting the name of a character on a favorite television show, “The Brady Bunch.”\n",
              "\n",
              "His decision to become a Christian, he told the pastors, did not come in one moment of lightning epiphany. Instead, he said, it happened in phases, growing from small seeds planted over time.\n",
              "\n",
              "Jindal recalled that his closest friend from grade school gave him a Bible with his name emblazoned in gold on the cover as a Christmas present. It struck him initially as an unimpressive gift, Jindal told the pastors.\n",
              "\n",
              "“Who in the world would spend good money for a Bible when everyone knows you can get one free in any hotel?” he recalled thinking at the time. “And the gold lettering meant I couldn’t give it away or return it.”\n",
              "\n",
              "His religious education reached a higher plane during his junior year in high school, he told his dinner audience. He wanted to ask a pretty girl on a date during a hallway conversation, and she started talking about her faith in God and her opposition to abortion. The girl invited him to visit her church.\n",
              "\n",
              "Jindal said he was skeptical and set out to “investigate all these fanciful claims” made by the girl and other friends. He started reading the Bible in his closet at home. “I was unsure how my parents would react,” he said.\n",
              "\n",
              "After the stirring moment when he saw Christ depicted on the cross during the religious movie, the Bible and his very existence suddenly seemed clearer to him, Jindal told the pastors.\n",
              "\n",
              "Jindal did not dwell on his subsequent conversion to Catholicism just a few years later in college, where he said he immersed himself in the traditions of the church.\n",
              "\n",
              "He touched on it briefly during the commencement address, noting in passing that “I am best described as an evangelical Catholic.” Mostly, he sought to showcase the ways in which he shares values with other Christian conservatives.\n",
              "\n",
              "“I read the words of Jesus Christ, and I realized that they were true,” Jindal told the graduates Saturday, offering a less detailed accounting of his conversion than he had done the night before with the pastors. “I used to think that I had found God, but I believe it is more accurate to say that He found me.”</td>\n",
              "      <td id=\"T_081ef_row3_col2\" class=\"data row3 col2\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_081ef_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_081ef_row4_col0\" class=\"data row4 col0\" >SATAN 2: Russia unvelis an image of its terrifying new ‘SUPERNUKE’ – Western world takes notice</td>\n",
              "      <td id=\"T_081ef_row4_col1\" class=\"data row4 col1\" >The RS-28 Sarmat missile, dubbed Satan 2, will replace the SS-18 Flies at 4.3 miles (7km) per sec and with a range of 6,213 miles (10,000km) The weapons are perceived as part of an increasingly aggressive Russia It could deliver a warhead of 40 megatons – 2,000 times as powerful as the atom bombs dropped on Hiroshima and Nagasaki in 1945 By LIBBY PLUMMER and GARETH DAVIE S Russia has unveiled chilling pictures of its largest ever nuclear missile, capable of destroying an area the size of France. The RS-28 Sarmat missile, dubbed Satan 2 by Nato, has a top speed of 4.3 miles (7km) per second and has been designed to outfox anti-missile shield systems. The new Sarmat missile could deliver warheads of 40 megatons – 2,000 times as powerful as the atom bombs dropped on Hiroshima and Nagasaki in 1945. Scroll down for video Russian President Vladimir Putin is reportedly planning to replace the country’s older SS-18 Satan weapons with the new missiles amid a string of recent disagreements with the West. The Kremlin has stepped up the rhetoric against the West and carried a series of manoeuvres that has infuriated politicians in the US and UK. The pictures were revealed online by chief designers from the Makeyev Rocket Design Bureau. A message posted alongside the picture said: ‘In accordance with the Decree of the Russian Government ‘On the State Defense Order for 2010 and the planning period 2012-2013’, the Makeyev Rocket Design Bureau was instructed to start design and development work on the Sarmat. ‘ The RS-28 Sarmat missile is said to contain 16 nuclear warheads and is capable of destroying an area the size of France or Texas, according to Russian news network Zvezda, which is owned by Russia’s ministry of defence. The weapon is also able to evade radar. It is expected to have a range of 6,213 miles (10,000 km), which would allow Moscow to attack London and \n",
              "FOR ENTIRE ARTICLE CLICK LINK</td>\n",
              "      <td id=\"T_081ef_row4_col2\" class=\"data row4 col2\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the text is very long, only the title will be used."
      ],
      "metadata": {
        "id": "9oPXzHuAgWd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove text column\n",
        "dataset_list = [[row[0]] + [row[-1]] for row in dataset_list]\n",
        "df = pd.DataFrame(dataset_list[1:6], columns=dataset_list[0])\n",
        "df.style"
      ],
      "metadata": {
        "id": "1eGm_WGGo6JO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d1fe0259-340c-4195-e4ea-cdf888c71813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7d7e7f614fa0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_4ab5b\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_4ab5b_level0_col0\" class=\"col_heading level0 col0\" >title</th>\n",
              "      <th id=\"T_4ab5b_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_4ab5b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_4ab5b_row0_col0\" class=\"data row0 col0\" >LAW ENFORCEMENT ON HIGH ALERT Following Threats Against Cops And Whites On 9-11By #BlackLivesMatter And #FYF911 Terrorists [VIDEO]</td>\n",
              "      <td id=\"T_4ab5b_row0_col1\" class=\"data row0 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4ab5b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_4ab5b_row1_col0\" class=\"data row1 col0\" ></td>\n",
              "      <td id=\"T_4ab5b_row1_col1\" class=\"data row1 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4ab5b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_4ab5b_row2_col0\" class=\"data row2 col0\" >UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MOST CHARLOTTE RIOTERS WERE “PEACEFUL” PROTESTERS…In Her Home State Of North Carolina [VIDEO]</td>\n",
              "      <td id=\"T_4ab5b_row2_col1\" class=\"data row2 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4ab5b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_4ab5b_row3_col0\" class=\"data row3 col0\" >Bobby Jindal, raised Hindu, uses story of Christian conversion to woo evangelicals for potential 2016 bid</td>\n",
              "      <td id=\"T_4ab5b_row3_col1\" class=\"data row3 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4ab5b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_4ab5b_row4_col0\" class=\"data row4 col0\" >SATAN 2: Russia unvelis an image of its terrifying new ‘SUPERNUKE’ – Western world takes notice</td>\n",
              "      <td id=\"T_4ab5b_row4_col1\" class=\"data row4 col1\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove entry with empty title"
      ],
      "metadata": {
        "id": "bUEqIWCgruEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove empty title\n",
        "dataset_list = [row for row in dataset_list if row[0]]\n",
        "df = pd.DataFrame(dataset_list[1:6], columns=dataset_list[0])\n",
        "df.style"
      ],
      "metadata": {
        "id": "cvXDh9ahrxgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a54e408b-776e-4079-ddfd-6f83efee4bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7d7e7f615c90>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_a0d2e\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_a0d2e_level0_col0\" class=\"col_heading level0 col0\" >title</th>\n",
              "      <th id=\"T_a0d2e_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_a0d2e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_a0d2e_row0_col0\" class=\"data row0 col0\" >LAW ENFORCEMENT ON HIGH ALERT Following Threats Against Cops And Whites On 9-11By #BlackLivesMatter And #FYF911 Terrorists [VIDEO]</td>\n",
              "      <td id=\"T_a0d2e_row0_col1\" class=\"data row0 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a0d2e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_a0d2e_row1_col0\" class=\"data row1 col0\" >UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MOST CHARLOTTE RIOTERS WERE “PEACEFUL” PROTESTERS…In Her Home State Of North Carolina [VIDEO]</td>\n",
              "      <td id=\"T_a0d2e_row1_col1\" class=\"data row1 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a0d2e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_a0d2e_row2_col0\" class=\"data row2 col0\" >Bobby Jindal, raised Hindu, uses story of Christian conversion to woo evangelicals for potential 2016 bid</td>\n",
              "      <td id=\"T_a0d2e_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a0d2e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_a0d2e_row3_col0\" class=\"data row3 col0\" >SATAN 2: Russia unvelis an image of its terrifying new ‘SUPERNUKE’ – Western world takes notice</td>\n",
              "      <td id=\"T_a0d2e_row3_col1\" class=\"data row3 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a0d2e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_a0d2e_row4_col0\" class=\"data row4 col0\" >About Time! Christian Group Sues Amazon and SPLC for Designation as Hate Group</td>\n",
              "      <td id=\"T_a0d2e_row4_col1\" class=\"data row4 col1\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset_list))"
      ],
      "metadata": {
        "id": "SraRhWikImB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee4549f-d91f-4f0f-e431-a5cb736e7721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove entry with empty label"
      ],
      "metadata": {
        "id": "kJa9TpTMIjDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_list = [row for row in dataset_list if row[1].isnumeric()]\n",
        "print(len(dataset_list))"
      ],
      "metadata": {
        "id": "FAG086BwIs0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502f2952-dfe0-47b3-ff5f-18044fc3c765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess Text"
      ],
      "metadata": {
        "id": "tMvbdSpHv1rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "0kmu7pJcst7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a0f4a3-6098-45ea-f682-8ec1be6306b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adapted from assignment 1\n",
        "def process_title(title):\n",
        "    \"\"\"Process tweet function.\n",
        "    Input:\n",
        "        title: a string containing a title\n",
        "    Output:\n",
        "        title_clean: a string of cleaned title\n",
        "\n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # only take alphabets\n",
        "    title = re.sub(r'[^a-zA-Z]', ' ', title)\n",
        "    # lower case\n",
        "    title = title.lower()\n",
        "    # tokenize\n",
        "    title_token = word_tokenize(title, language='english', preserve_line=False)\n",
        "\n",
        "    title_clean = \"\"\n",
        "    for word in title_token:\n",
        "        if (word not in stopwords_english): # remove stopwords\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            title_clean =  title_clean + \" \" + stem_word\n",
        "\n",
        "    return title_clean"
      ],
      "metadata": {
        "id": "-N9JHLkuv3zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test preprocess_title"
      ],
      "metadata": {
        "id": "cLQx5PyF9QMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(process_title(dataset_list[1][0]))\n",
        "print(\"\\n\" + dataset_list[1][0])"
      ],
      "metadata": {
        "id": "Ca_6vjdt9SnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee91ea01-835c-447f-8318-9def6dd367ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " unbeliev obama attorney gener say charlott rioter peac protest home state north carolina video\n",
            "\n",
            "UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MOST CHARLOTTE RIOTERS WERE “PEACEFUL” PROTESTERS…In Her Home State Of North Carolina [VIDEO]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the dataset"
      ],
      "metadata": {
        "id": "IEf6Xg3O_Y9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for row in dataset_list:\n",
        "  row[0] = process_title(row[0])"
      ],
      "metadata": {
        "id": "EXXmBw6O_b--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See Preprocessed title"
      ],
      "metadata": {
        "id": "YcQ9Sf7O_28M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(dataset_list[:20], columns=[\"title\", \"label\"])\n",
        "df.style"
      ],
      "metadata": {
        "id": "rQYM83kJ_4py",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "efcbede9-1e72-47b5-bb87-a77a8a8356c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7d7e8a9615a0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_547e2\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_547e2_level0_col0\" class=\"col_heading level0 col0\" >title</th>\n",
              "      <th id=\"T_547e2_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_547e2_row0_col0\" class=\"data row0 col0\" > law enforc high alert follow threat cop white blacklivesmatt fyf terrorist video</td>\n",
              "      <td id=\"T_547e2_row0_col1\" class=\"data row0 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_547e2_row1_col0\" class=\"data row1 col0\" > unbeliev obama attorney gener say charlott rioter peac protest home state north carolina video</td>\n",
              "      <td id=\"T_547e2_row1_col1\" class=\"data row1 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_547e2_row2_col0\" class=\"data row2 col0\" > bobbi jindal rais hindu use stori christian convers woo evangel potenti bid</td>\n",
              "      <td id=\"T_547e2_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_547e2_row3_col0\" class=\"data row3 col0\" > satan russia unv imag terrifi new supernuk western world take notic</td>\n",
              "      <td id=\"T_547e2_row3_col1\" class=\"data row3 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_547e2_row4_col0\" class=\"data row4 col0\" > time christian group sue amazon splc design hate group</td>\n",
              "      <td id=\"T_547e2_row4_col1\" class=\"data row4 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_547e2_row5_col0\" class=\"data row5 col0\" > dr ben carson target ir never audit spoke nation prayer breakfast</td>\n",
              "      <td id=\"T_547e2_row5_col1\" class=\"data row5 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_547e2_row6_col0\" class=\"data row6 col0\" > hous intel chair trump russia fake stori evid anyth video</td>\n",
              "      <td id=\"T_547e2_row6_col1\" class=\"data row6 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_547e2_row7_col0\" class=\"data row7 col0\" > sport bar owner ban nfl game show true american sport like speak rural america video</td>\n",
              "      <td id=\"T_547e2_row7_col1\" class=\"data row7 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_547e2_row8_col0\" class=\"data row8 col0\" > latest pipelin leak underscor danger dakota access pipelin</td>\n",
              "      <td id=\"T_547e2_row8_col1\" class=\"data row8 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_547e2_row9_col0\" class=\"data row9 col0\" > gop senat smack punchabl alt right nazi internet</td>\n",
              "      <td id=\"T_547e2_row9_col1\" class=\"data row9 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_547e2_row10_col0\" class=\"data row10 col0\" > may brexit offer would hurt cost eu citizen eu parliament</td>\n",
              "      <td id=\"T_547e2_row10_col1\" class=\"data row10 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_547e2_row11_col0\" class=\"data row11 col0\" > schumer call trump appoint offici overse puerto rico relief</td>\n",
              "      <td id=\"T_547e2_row11_col1\" class=\"data row11 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_547e2_row12_col0\" class=\"data row12 col0\" > watch hilari ad call question health age clinton crime famili boss</td>\n",
              "      <td id=\"T_547e2_row12_col1\" class=\"data row12 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_547e2_row13_col0\" class=\"data row13 col0\" > chang expect espn polit agenda despit huge subscrib declin breitbart</td>\n",
              "      <td id=\"T_547e2_row13_col1\" class=\"data row13 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_547e2_row14_col0\" class=\"data row14 col0\" > billionair odebrecht brazil scandal releas hous arrest</td>\n",
              "      <td id=\"T_547e2_row14_col1\" class=\"data row14 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_547e2_row15_col0\" class=\"data row15 col0\" > british woman lose virgin asylum seek rapist way church</td>\n",
              "      <td id=\"T_547e2_row15_col1\" class=\"data row15 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_547e2_row16_col0\" class=\"data row16 col0\" > u n seek humanitarian paus sanaa street battleground</td>\n",
              "      <td id=\"T_547e2_row16_col1\" class=\"data row16 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_547e2_row17_col0\" class=\"data row17 col0\" > major liber rag reluctantli publish articl presid trump outstand accomplish explain success everyon laugh</td>\n",
              "      <td id=\"T_547e2_row17_col1\" class=\"data row17 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_547e2_row18_col0\" class=\"data row18 col0\" > second judg say clinton email setup may bad faith</td>\n",
              "      <td id=\"T_547e2_row18_col1\" class=\"data row18 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_547e2_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_547e2_row19_col0\" class=\"data row19 col0\" > america give grand piano hors</td>\n",
              "      <td id=\"T_547e2_row19_col1\" class=\"data row19 col1\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Define model"
      ],
      "metadata": {
        "id": "5lxpSaUHAOwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "D6QsQu6oBCT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into corpus and labels"
      ],
      "metadata": {
        "id": "3pb2atuqGXQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [row[0] for row in dataset_list]\n",
        "label = [int(row[1]) for row in dataset_list]"
      ],
      "metadata": {
        "id": "QS7D9780BC5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  print(corpus[i], label[i])"
      ],
      "metadata": {
        "id": "9Oj0E2mMG157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3ac183-7e85-4bd5-bd61-62d356e8a4e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " law enforc high alert follow threat cop white blacklivesmatt fyf terrorist video 1\n",
            " unbeliev obama attorney gener say charlott rioter peac protest home state north carolina video 1\n",
            " bobbi jindal rais hindu use stori christian convers woo evangel potenti bid 0\n",
            " satan russia unv imag terrifi new supernuk western world take notic 1\n",
            " time christian group sue amazon splc design hate group 1\n",
            " dr ben carson target ir never audit spoke nation prayer breakfast 1\n",
            " hous intel chair trump russia fake stori evid anyth video 1\n",
            " sport bar owner ban nfl game show true american sport like speak rural america video 1\n",
            " latest pipelin leak underscor danger dakota access pipelin 1\n",
            " gop senat smack punchabl alt right nazi internet 1\n",
            " may brexit offer would hurt cost eu citizen eu parliament 0\n",
            " schumer call trump appoint offici overse puerto rico relief 0\n",
            " watch hilari ad call question health age clinton crime famili boss 1\n",
            " chang expect espn polit agenda despit huge subscrib declin breitbart 0\n",
            " billionair odebrecht brazil scandal releas hous arrest 0\n",
            " british woman lose virgin asylum seek rapist way church 1\n",
            " u n seek humanitarian paus sanaa street battleground 0\n",
            " major liber rag reluctantli publish articl presid trump outstand accomplish explain success everyon laugh 1\n",
            " second judg say clinton email setup may bad faith 0\n",
            " america give grand piano hors 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into training and test set."
      ],
      "metadata": {
        "id": "Xk6ryUN7LIne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = len(label)\n",
        "split_size = int(dataset_size * 0.8)\n",
        "x_train = np.array(corpus[:split_size])\n",
        "y_train =  np.array(label[:split_size])\n",
        "x_test =  np.array(corpus[split_size:])\n",
        "y_test =  np.array(label[split_size:])"
      ],
      "metadata": {
        "id": "_a4cphKuLRCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check label distribution"
      ],
      "metadata": {
        "id": "CXyr-BdvL8_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sum = 0\n",
        "test_sum = 0\n",
        "for i in y_train:\n",
        "  train_sum += i\n",
        "for i in y_test:\n",
        "  test_sum += i\n",
        "\n",
        "print(\"training set:\", train_sum/split_size)\n",
        "print(\"test set:\", test_sum/(dataset_size-split_size))"
      ],
      "metadata": {
        "id": "pldYuITIL_64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a871ef-3c79-45a0-c8f9-82479fcc06b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set: 0.5104785190359763\n",
            "test set: 0.5111763062307907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Vectorization"
      ],
      "metadata": {
        "id": "l5KGE88ZM051"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer = TextVectorization(output_mode=\"int\")\n",
        "text_vectorizer.adapt(x_train)"
      ],
      "metadata": {
        "id": "hYkfDH-HM0lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(text_vectorizer(x_train[200+i]).numpy())\n",
        "  print(x_train[200+i])"
      ],
      "metadata": {
        "id": "5g_zE44uQAMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d80fa95-82ac-4df9-e186-91529fcfdbc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 191  390 3204  316  650 3213 6900  898  426   39  417]\n",
            " famili arm robberi suspect outrag pizza hut employe shot kill son\n",
            "[  59    2  553 2769    2   29  185  409  428 2129    3]\n",
            " anti trump radic taunt trump support isi flag photo behead video\n",
            "[ 279 3819 4414  704   85  146   32  683  166  277    3]\n",
            " wow atlanta gym owner ban cop make apolog polici sign video\n",
            "[ 699   12  340 2978  277  152 1112 3911    4    6    5]\n",
            " turkish presid return istanbul sign militari coup falter new york time\n",
            "[  112  4743   650  4826  4893    18 13611   678  6562  1001   421 12036]\n",
            " comment sjw outrag leonardo dicaprio white rumi role unfound iranian explain ztech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define sequential model\n",
        "\n",
        "User binary_crossentropy because output is 0 or 1"
      ],
      "metadata": {
        "id": "WuZdVk6xSsKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=text_vectorizer.vocabulary_size(), output_dim=32))\n",
        "model.add(LSTM(128, input_shape=(1,32), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_68LiFPnSvyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf99920-8b3c-4ab0-d8df-490d276b51d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 32)          583808    \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, None, 128)         82432     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, None, 128)         0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 797953 (3.04 MB)\n",
            "Trainable params: 797953 (3.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Define checkpoint"
      ],
      "metadata": {
        "id": "zZWZvnWYAV3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"LSTM-model2-weights-improvement-{epoch:02d}-{loss:.4f}-bigger.keras\"\n",
        "checkpoint_LSTM = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list_LSTM = [checkpoint_LSTM]"
      ],
      "metadata": {
        "id": "U6IvGcKPUSv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Fit model\n"
      ],
      "metadata": {
        "id": "7bi3ME7yAaAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text vectorize training and testing set"
      ],
      "metadata": {
        "id": "lzRiXKWuUgnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_v = [text_vectorizer(text) for text in x_train]\n",
        "x_test_v = [text_vectorizer(text) for text in x_test]"
      ],
      "metadata": {
        "id": "1hcS7ThiUkaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See vectorized titles"
      ],
      "metadata": {
        "id": "l63CnB6EW0WL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  print(x_train_v[1000+i])"
      ],
      "metadata": {
        "id": "WRJiC7MgW-jC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d10eb5-8c85-465e-f522-dbd4aecf2d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 251 6666  373 2579 4714  692  421 1086 1380  542], shape=(10,), dtype=int64)\n",
            "tf.Tensor([ 182 1326  202 2361  243  291   75], shape=(7,), dtype=int64)\n",
            "tf.Tensor([ 423   57   32 1798 2155 7956], shape=(6,), dtype=int64)\n",
            "tf.Tensor([  164    72  3052 11140   514  9335], shape=(6,), dtype=int64)\n",
            "tf.Tensor([ 352 1391 3576  877  309 3352 7119   22 1842 7120 2000  133   14], shape=(13,), dtype=int64)\n",
            "tf.Tensor([1933  154  139 1066 1423  400  211  653], shape=(8,), dtype=int64)\n",
            "tf.Tensor([ 221  535  775 2078 2806    2  379 1140  768], shape=(9,), dtype=int64)\n",
            "tf.Tensor([    2   179    41   564  2793    96 16854    44  2331], shape=(9,), dtype=int64)\n",
            "tf.Tensor([  18   13  893 1391 1373  388    2   44  427  300    2 3206], shape=(12,), dtype=int64)\n",
            "tf.Tensor([   2    8   63  791  111  118 2729  264], shape=(8,), dtype=int64)\n",
            "tf.Tensor([ 25 643 966 177 248  72  70], shape=(7,), dtype=int64)\n",
            "tf.Tensor([ 400    8  123 2641  340  653  137], shape=(7,), dtype=int64)\n",
            "tf.Tensor([  41 1629 1110  476 4107   45 4925], shape=(7,), dtype=int64)\n",
            "tf.Tensor([1768 1975    5 3917  231    2 5109 9145   14], shape=(9,), dtype=int64)\n",
            "tf.Tensor([12060 16992   830    20   230], shape=(5,), dtype=int64)\n",
            "tf.Tensor([1901 3294  643 2273 3841  187  761], shape=(7,), dtype=int64)\n",
            "tf.Tensor([ 301    8   74  377  117 2687], shape=(6,), dtype=int64)\n",
            "tf.Tensor([  33 3147  836  192  298   25   12  370 1578], shape=(9,), dtype=int64)\n",
            "tf.Tensor([ 31 149  57 511  19   2 133 827], shape=(8,), dtype=int64)\n",
            "tf.Tensor([ 793  657   55   27 2104   55  146 1907    3], shape=(9,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('x_train_v.csv', 'w') as f:\n",
        "    write = csv.writer(f)\n",
        "with open('x_test_v.csv', 'w') as f:\n",
        "    write = csv.writer(f)"
      ],
      "metadata": {
        "id": "-rdVeNk_XiGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pad sequence to equal length"
      ],
      "metadata": {
        "id": "8Vt6qRz8YZVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_vp = pad_sequences(x_train_v, padding=\"post\")\n",
        "x_test_vp = pad_sequences(x_test_v, padding=\"post\")"
      ],
      "metadata": {
        "id": "K7AkBT3SYchk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit model"
      ],
      "metadata": {
        "id": "sS5tRLDEYCIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train_vp, y_train, epochs=10, batch_size=64, validation_split=0.2, callbacks=callbacks_list_LSTM)"
      ],
      "metadata": {
        "id": "5dWmOg-PYDuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b283fc-dda1-47d3-d1df-8d3247b0ee98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.4183 - accuracy: 0.7669\n",
            "Epoch 1: loss improved from inf to 0.41825, saving model to LSTM-model2-weights-improvement-01-0.4183-bigger.keras\n",
            "716/716 [==============================] - 205s 278ms/step - loss: 0.4183 - accuracy: 0.7669 - val_loss: 0.2706 - val_accuracy: 0.8901\n",
            "Epoch 2/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.9161\n",
            "Epoch 2: loss improved from 0.41825 to 0.21879, saving model to LSTM-model2-weights-improvement-02-0.2188-bigger.keras\n",
            "716/716 [==============================] - 179s 251ms/step - loss: 0.2188 - accuracy: 0.9161 - val_loss: 0.2533 - val_accuracy: 0.8998\n",
            "Epoch 3/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9309\n",
            "Epoch 3: loss improved from 0.21879 to 0.18299, saving model to LSTM-model2-weights-improvement-03-0.1830-bigger.keras\n",
            "716/716 [==============================] - 190s 265ms/step - loss: 0.1830 - accuracy: 0.9309 - val_loss: 0.2571 - val_accuracy: 0.8981\n",
            "Epoch 4/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.1577 - accuracy: 0.9404\n",
            "Epoch 4: loss improved from 0.18299 to 0.15773, saving model to LSTM-model2-weights-improvement-04-0.1577-bigger.keras\n",
            "716/716 [==============================] - 191s 267ms/step - loss: 0.1577 - accuracy: 0.9404 - val_loss: 0.2679 - val_accuracy: 0.8943\n",
            "Epoch 5/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9458\n",
            "Epoch 5: loss improved from 0.15773 to 0.13833, saving model to LSTM-model2-weights-improvement-05-0.1383-bigger.keras\n",
            "716/716 [==============================] - 200s 279ms/step - loss: 0.1383 - accuracy: 0.9458 - val_loss: 0.2780 - val_accuracy: 0.8948\n",
            "Epoch 6/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.9498\n",
            "Epoch 6: loss improved from 0.13833 to 0.12330, saving model to LSTM-model2-weights-improvement-06-0.1233-bigger.keras\n",
            "716/716 [==============================] - 195s 272ms/step - loss: 0.1233 - accuracy: 0.9498 - val_loss: 0.2891 - val_accuracy: 0.8940\n",
            "Epoch 7/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9575\n",
            "Epoch 7: loss improved from 0.12330 to 0.10413, saving model to LSTM-model2-weights-improvement-07-0.1041-bigger.keras\n",
            "716/716 [==============================] - 194s 272ms/step - loss: 0.1041 - accuracy: 0.9575 - val_loss: 0.3615 - val_accuracy: 0.8953\n",
            "Epoch 8/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9630\n",
            "Epoch 8: loss improved from 0.10413 to 0.08782, saving model to LSTM-model2-weights-improvement-08-0.0878-bigger.keras\n",
            "716/716 [==============================] - 189s 264ms/step - loss: 0.0878 - accuracy: 0.9630 - val_loss: 0.3530 - val_accuracy: 0.8943\n",
            "Epoch 9/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.9694\n",
            "Epoch 9: loss improved from 0.08782 to 0.07586, saving model to LSTM-model2-weights-improvement-09-0.0759-bigger.keras\n",
            "716/716 [==============================] - 189s 264ms/step - loss: 0.0759 - accuracy: 0.9694 - val_loss: 0.4359 - val_accuracy: 0.8869\n",
            "Epoch 10/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9741\n",
            "Epoch 10: loss improved from 0.07586 to 0.06683, saving model to LSTM-model2-weights-improvement-10-0.0668-bigger.keras\n",
            "716/716 [==============================] - 188s 263ms/step - loss: 0.0668 - accuracy: 0.9741 - val_loss: 0.4320 - val_accuracy: 0.8957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d7e7c4e17e0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Test the model and metrics such as accuracy, precision, recall, and F1-score"
      ],
      "metadata": {
        "id": "CzopGlPdbTjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model with least training loss VS least validation loss"
      ],
      "metadata": {
        "id": "3S3EHxXDucva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss = Sequential()\n",
        "model_loss.add(Embedding(input_dim=text_vectorizer.vocabulary_size(), output_dim=32))\n",
        "model_loss.add(LSTM(128, input_shape=(1,32), return_sequences=True))\n",
        "model_loss.add(Dropout(0.2))\n",
        "model_loss.add(LSTM(128))\n",
        "model_loss.add(Dropout(0.2))\n",
        "model_loss.add(Dense(1, activation='sigmoid'))\n",
        "model_loss.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_loss.summary()\n",
        "\n",
        "model_val_loss = Sequential()\n",
        "model_val_loss.add(Embedding(input_dim=text_vectorizer.vocabulary_size(), output_dim=32))\n",
        "model_val_loss.add(LSTM(128, input_shape=(1,32), return_sequences=True))\n",
        "model_val_loss.add(Dropout(0.2))\n",
        "model_val_loss.add(LSTM(128))\n",
        "model_val_loss.add(Dropout(0.2))\n",
        "model_val_loss.add(Dense(1, activation='sigmoid'))\n",
        "model_val_loss.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_val_loss.summary()"
      ],
      "metadata": {
        "id": "x-NE4hYsvV44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ceacd3e-f3a1-4485-e7f6-c5f6fee24882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, None, 32)          583808    \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, None, 128)         82432     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, None, 128)         0         \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 797953 (3.04 MB)\n",
            "Trainable params: 797953 (3.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, None, 32)          583808    \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, None, 128)         82432     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, None, 128)         0         \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 797953 (3.04 MB)\n",
            "Trainable params: 797953 (3.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#least training loss - Epoch 10\n",
        "filename_loss = \"/content/LSTM-model2-weights-improvement-10-0.0668-bigger.keras\"\n",
        "model_loss.load_weights(filename_loss)\n",
        "model_loss.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vRTkJklfbhiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a934f95-4702-4719-dba2-137857ab3e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 19 variables. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#least validation loss - Epoch 3\n",
        "filename_val_loss = \"/content/LSTM-model2-weights-improvement-03-0.1830-bigger.keras\"\n",
        "model_val_loss.load_weights(filename_val_loss)\n",
        "model_val_loss.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fEcRxCfVusmK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d76e35-e074-4ba2-8cab-07b80b9e9a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 19 variables. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict on test set"
      ],
      "metadata": {
        "id": "oofhbISEv5M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_loss = model_loss.predict(x_test_vp)\n",
        "y_predict_val_loss = model_val_loss.predict(x_test_vp)"
      ],
      "metadata": {
        "id": "1rt53u0Av78W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d84434-11cd-4dd3-d73b-667507f78950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448/448 [==============================] - 18s 37ms/step\n",
            "448/448 [==============================] - 18s 37ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_loss = y_predict_loss.round()\n",
        "y_predict_val_loss = y_predict_val_loss.round()"
      ],
      "metadata": {
        "id": "HhUyZh0V0wdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics"
      ],
      "metadata": {
        "id": "dOzklJJXv8Pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "#y_test is label\n",
        "#y_predict is prediction\n",
        "print(\"Least training loss:\\n\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_predict_loss))\n",
        "print( classification_report(y_test, y_predict_loss))\n",
        "print(\"\\nLeast validation loss:\\n\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_predict_val_loss))\n",
        "print( classification_report(y_test, y_predict_val_loss))"
      ],
      "metadata": {
        "id": "okH0Kw5jv9xD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dbda438-991a-4c7f-cf24-4fa90d3efbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Least training loss:\n",
            "\n",
            "Accuracy: 0.8640681754680078\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.85      0.86      6998\n",
            "           1       0.86      0.87      0.87      7318\n",
            "\n",
            "    accuracy                           0.86     14316\n",
            "   macro avg       0.86      0.86      0.86     14316\n",
            "weighted avg       0.86      0.86      0.86     14316\n",
            "\n",
            "\n",
            "Least validation loss:\n",
            "\n",
            "Accuracy: 0.877689298686784\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.82      0.87      6998\n",
            "           1       0.84      0.93      0.89      7318\n",
            "\n",
            "    accuracy                           0.88     14316\n",
            "   macro avg       0.88      0.88      0.88     14316\n",
            "weighted avg       0.88      0.88      0.88     14316\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "#BiLSTM"
      ],
      "metadata": {
        "id": "usNHv1pVAiSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Define model\n"
      ],
      "metadata": {
        "id": "W687ZNDCAxZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Bidirectional"
      ],
      "metadata": {
        "id": "lyTJCjF7U4n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define sequential model"
      ],
      "metadata": {
        "id": "eRDXe6i0VJPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using two Bidirectional layers"
      ],
      "metadata": {
        "id": "O7ixJmzAVzZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_bi = Sequential()\n",
        "model_bi.add(Embedding(input_dim=text_vectorizer.vocabulary_size(), output_dim=32))\n",
        "model_bi.add(Bidirectional(LSTM(64, input_shape=(1,32), return_sequences=True)))\n",
        "model_bi.add(Dropout(0.2))\n",
        "model_bi.add(Bidirectional(LSTM(64)))\n",
        "model_bi.add(Dropout(0.2))\n",
        "model_bi.add(Dense(1, activation='sigmoid'))\n",
        "model_bi.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_bi.summary()"
      ],
      "metadata": {
        "id": "qR_fqjX7VKrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f5411f-b317-4017-c500-841c7929a237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, None, 32)          583808    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, None, 128)         49664     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, None, 128)         0         \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 128)               98816     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 732417 (2.79 MB)\n",
            "Trainable params: 732417 (2.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Define checkpoint"
      ],
      "metadata": {
        "id": "DU993j9JA1B1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath_BiLSTM = \"BiLSTM-model2-weights-improvement-{epoch:02d}-{loss:.4f}-bigger.keras\"\n",
        "checkpoint_BiLSTM = ModelCheckpoint(filepath_BiLSTM, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list_BiLSTM = [checkpoint_BiLSTM]"
      ],
      "metadata": {
        "id": "-4TsmTD9Vyhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Fit model\n"
      ],
      "metadata": {
        "id": "M8WUQgEHA3O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_bi.fit(x_train_vp, y_train, epochs=10, batch_size=64, validation_split=0.2, callbacks=callbacks_list_BiLSTM)"
      ],
      "metadata": {
        "id": "ySGoUknyV9Cy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eee564a-dc51-4b7b-f235-b3c18a27e91a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.2839 - accuracy: 0.8766\n",
            "Epoch 1: loss improved from inf to 0.28393, saving model to BiLSTM-model2-weights-improvement-01-0.2839-bigger.keras\n",
            "716/716 [==============================] - 220s 229ms/step - loss: 0.2839 - accuracy: 0.8766 - val_loss: 0.2306 - val_accuracy: 0.9087\n",
            "Epoch 2/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 0.9358\n",
            "Epoch 2: loss improved from 0.28393 to 0.16783, saving model to BiLSTM-model2-weights-improvement-02-0.1678-bigger.keras\n",
            "716/716 [==============================] - 150s 209ms/step - loss: 0.1678 - accuracy: 0.9358 - val_loss: 0.2306 - val_accuracy: 0.9081\n",
            "Epoch 3/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9530\n",
            "Epoch 3: loss improved from 0.16783 to 0.12671, saving model to BiLSTM-model2-weights-improvement-03-0.1267-bigger.keras\n",
            "716/716 [==============================] - 152s 211ms/step - loss: 0.1267 - accuracy: 0.9530 - val_loss: 0.2581 - val_accuracy: 0.9046\n",
            "Epoch 4/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9640\n",
            "Epoch 4: loss improved from 0.12671 to 0.09713, saving model to BiLSTM-model2-weights-improvement-04-0.0971-bigger.keras\n",
            "716/716 [==============================] - 151s 211ms/step - loss: 0.0971 - accuracy: 0.9640 - val_loss: 0.2731 - val_accuracy: 0.9003\n",
            "Epoch 5/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9715\n",
            "Epoch 5: loss improved from 0.09713 to 0.07910, saving model to BiLSTM-model2-weights-improvement-05-0.0791-bigger.keras\n",
            "716/716 [==============================] - 160s 224ms/step - loss: 0.0791 - accuracy: 0.9715 - val_loss: 0.3174 - val_accuracy: 0.8999\n",
            "Epoch 6/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9785\n",
            "Epoch 6: loss improved from 0.07910 to 0.06022, saving model to BiLSTM-model2-weights-improvement-06-0.0602-bigger.keras\n",
            "716/716 [==============================] - 150s 210ms/step - loss: 0.0602 - accuracy: 0.9785 - val_loss: 0.3718 - val_accuracy: 0.8975\n",
            "Epoch 7/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9824\n",
            "Epoch 7: loss improved from 0.06022 to 0.04802, saving model to BiLSTM-model2-weights-improvement-07-0.0480-bigger.keras\n",
            "716/716 [==============================] - 148s 207ms/step - loss: 0.0480 - accuracy: 0.9824 - val_loss: 0.4809 - val_accuracy: 0.8986\n",
            "Epoch 8/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9853\n",
            "Epoch 8: loss improved from 0.04802 to 0.03850, saving model to BiLSTM-model2-weights-improvement-08-0.0385-bigger.keras\n",
            "716/716 [==============================] - 160s 223ms/step - loss: 0.0385 - accuracy: 0.9853 - val_loss: 0.4492 - val_accuracy: 0.8977\n",
            "Epoch 9/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9878\n",
            "Epoch 9: loss improved from 0.03850 to 0.03367, saving model to BiLSTM-model2-weights-improvement-09-0.0337-bigger.keras\n",
            "716/716 [==============================] - 150s 209ms/step - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.4858 - val_accuracy: 0.8965\n",
            "Epoch 10/10\n",
            "716/716 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9908\n",
            "Epoch 10: loss improved from 0.03367 to 0.02623, saving model to BiLSTM-model2-weights-improvement-10-0.0262-bigger.keras\n",
            "716/716 [==============================] - 150s 209ms/step - loss: 0.0262 - accuracy: 0.9908 - val_loss: 0.5539 - val_accuracy: 0.8947\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d7e874ef6a0>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Test the model and metrics"
      ],
      "metadata": {
        "id": "tPPB71oEWNdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_bi_loss = Sequential()\n",
        "model_bi_loss.add(Embedding(input_dim=text_vectorizer.vocabulary_size(), output_dim=32))\n",
        "model_bi_loss.add(LSTM(64, input_shape=(1,32), return_sequences=True))\n",
        "model_bi_loss.add(Dropout(0.2))\n",
        "model_bi_loss.add(LSTM(64))\n",
        "model_bi_loss.add(Dropout(0.2))\n",
        "model_bi_loss.add(Dense(1, activation='sigmoid'))\n",
        "model_bi_loss.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_bi_loss.summary()\n",
        "\n",
        "model_bi_val_loss = Sequential()\n",
        "model_bi_val_loss.add(Embedding(input_dim=text_vectorizer.vocabulary_size(), output_dim=32))\n",
        "model_bi_val_loss.add(LSTM(64, input_shape=(1,32), return_sequences=True))\n",
        "model_bi_val_loss.add(Dropout(0.2))\n",
        "model_bi_val_loss.add(LSTM(64))\n",
        "model_bi_val_loss.add(Dropout(0.2))\n",
        "model_bi_val_loss.add(Dense(1, activation='sigmoid'))\n",
        "model_bi_val_loss.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_bi_val_loss.summary()"
      ],
      "metadata": {
        "id": "t2EAw7CAWQ9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42bf8953-3dfb-4d58-8b8e-3552f412e6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, None, 32)          583808    \n",
            "                                                                 \n",
            " lstm_24 (LSTM)              (None, None, 64)          24832     \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, None, 64)          0         \n",
            "                                                                 \n",
            " lstm_25 (LSTM)              (None, 64)                33024     \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 641729 (2.45 MB)\n",
            "Trainable params: 641729 (2.45 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    (None, None, 32)          583808    \n",
            "                                                                 \n",
            " lstm_26 (LSTM)              (None, None, 64)          24832     \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, None, 64)          0         \n",
            "                                                                 \n",
            " lstm_27 (LSTM)              (None, 64)                33024     \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 641729 (2.45 MB)\n",
            "Trainable params: 641729 (2.45 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#least training loss - Epoch 9\n",
        "filename_loss = \"/content/BiLSTM-model2-weights-improvement-09-0.0337-bigger.keras\"\n",
        "model_bi_loss.load_weights(filename_loss)\n",
        "model_bi_loss.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fqltbmPzWkGL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "46a8aef6-70e2-429f-b8b7-a63468bac50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 31 variables. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Layer 'lstm_cell' expected 3 variables, but received 0 variables during loading. Expected: ['lstm_24/lstm_cell/kernel:0', 'lstm_24/lstm_cell/recurrent_kernel:0', 'lstm_24/lstm_cell/bias:0']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-094c2a9488e2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#least training loss - Epoch 9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/BiLSTM-model2-weights-improvement-09-0.0337-bigger.keras\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_bi_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel_bi_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36mload_own_variables\u001b[0;34m(self, store)\u001b[0m\n\u001b[1;32m   3529\u001b[0m         \u001b[0mall_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_trainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3531\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3532\u001b[0m                 \u001b[0;34mf\"Layer '{self.name}' expected {len(all_vars)} variables, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3533\u001b[0m                 \u001b[0;34m\"but received \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer 'lstm_cell' expected 3 variables, but received 0 variables during loading. Expected: ['lstm_24/lstm_cell/kernel:0', 'lstm_24/lstm_cell/recurrent_kernel:0', 'lstm_24/lstm_cell/bias:0']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#least validation loss - Epoch 5\n",
        "filename_val_loss = \"/content/BiLSTM-model2-weights-improvement-05-0.0791-bigger.keras\"\n",
        "model_bi_val_loss.load_weights(filename_val_loss)\n",
        "model_bi_val_loss.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "e-AZC7fVWkp6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "58755a94-8315-430e-a3c0-ee5fe4a87746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 31 variables. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Layer 'lstm_cell' expected 3 variables, but received 0 variables during loading. Expected: ['lstm_26/lstm_cell/kernel:0', 'lstm_26/lstm_cell/recurrent_kernel:0', 'lstm_26/lstm_cell/bias:0']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-06721225c59c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#least validation loss - Epoch 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/BiLSTM-model2-weights-improvement-05-0.0791-bigger.keras\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_bi_val_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_val_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel_bi_val_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36mload_own_variables\u001b[0;34m(self, store)\u001b[0m\n\u001b[1;32m   3529\u001b[0m         \u001b[0mall_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_trainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3531\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3532\u001b[0m                 \u001b[0;34mf\"Layer '{self.name}' expected {len(all_vars)} variables, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3533\u001b[0m                 \u001b[0;34m\"but received \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer 'lstm_cell' expected 3 variables, but received 0 variables during loading. Expected: ['lstm_26/lstm_cell/kernel:0', 'lstm_26/lstm_cell/recurrent_kernel:0', 'lstm_26/lstm_cell/bias:0']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_bi_loss = model_bi.predict(x_test_vp)\n",
        "y_predict_bi_val_loss = model_bi_val_loss.predict(x_test_vp)"
      ],
      "metadata": {
        "id": "A9MdA84zWuqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7bb75b-54e5-4753-bbbb-dd63724812a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448/448 [==============================] - 11s 21ms/step\n",
            "448/448 [==============================] - 6s 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_bi_loss = y_predict_bi_loss.round()\n",
        "y_predict_bi_val_loss = y_predict_bi_val_loss.round()"
      ],
      "metadata": {
        "id": "jo5Mvb9gW4W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "#y_test is label\n",
        "#y_predict is prediction\n",
        "print(\"Least training loss:\\n\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_predict_bi_loss))\n",
        "print( classification_report(y_test, y_predict_bi_loss))\n",
        "print(\"\\nLeast validation loss:\\n\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_predict_bi_val_loss))\n",
        "print( classification_report(y_test, y_predict_val_loss))"
      ],
      "metadata": {
        "id": "nFI8ZO_eW_Jl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35aa1bdf-2e17-4aa0-c7d8-752afc6f2380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Least training loss:\n",
            "\n",
            "Accuracy: 0.896968426934898\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.88      0.89      6998\n",
            "           1       0.89      0.92      0.90      7318\n",
            "\n",
            "    accuracy                           0.90     14316\n",
            "   macro avg       0.90      0.90      0.90     14316\n",
            "weighted avg       0.90      0.90      0.90     14316\n",
            "\n",
            "\n",
            "Least validation loss:\n",
            "\n",
            "Accuracy: 0.5007683710533669\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.82      0.87      6998\n",
            "           1       0.84      0.93      0.89      7318\n",
            "\n",
            "    accuracy                           0.88     14316\n",
            "   macro avg       0.88      0.88      0.88     14316\n",
            "weighted avg       0.88      0.88      0.88     14316\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Member Group 13"
      ],
      "metadata": {
        "id": "JMXtSm72lZY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Members Group 13**\n",
        "```\n",
        "Jessada Peetapa\t     6422770915\t 6422770915@g.siit.tu.ac.th\n",
        "Matas Thanamee\t      6422771251\t 6422771251@g.siit.tu.ac.th\n",
        "Woramate Simrum\t     6422771400\t 6422771400@g.siit.tu.ac.th\n",
        "Napat Khowyabud\t     6422772051\t 6422772051@g.siit.tu.ac.th\n",
        "Pavida Pipatanagovit    6422772069\t 6422772069@g.siit.tu.ac.th\n",
        "```"
      ],
      "metadata": {
        "id": "QPbxS-dLlgfS"
      }
    }
  ]
}